{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DcroWxDA19x"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split  # Library for split dataset into train and test dataset\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "# CREA UNA LISTA DI TUTTE LE IMMAGINI NELLA CARTELLA\n",
    "def create_filelist(path, format):\n",
    "    filelist = []\n",
    "    for root, dirs, files in os.walk(path):  # os.walk returns a generator, that creates a tuple of values (current_path, directories in current_path, files in current_path).\n",
    "        for file in files:\n",
    "            if(file.endswith(\".\"+format)):\n",
    "                #append the file name to the list\n",
    "                filelist.append(os.path.join(root,file))\n",
    "    #print('PNG images found in ' + path + ': ', len(filelist))            \n",
    "    return filelist\n",
    "\n",
    "\n",
    "# RITORNA LA LABEL DELL'IMMAGINE DATO IL SUO PATH\n",
    "def path_to_label(path):\n",
    "    file_name_parts = path.split('/')\n",
    "    img_name = file_name_parts[-1]\n",
    "    img_name_parts = img_name.split('_')\n",
    "    return img_name_parts[-1].split('.')[0]\n",
    "\n",
    "\n",
    "# RITORNA UNA LISTA DI IMMAGINI DEL DATASET E UNA LISTA DI LABEL\n",
    "def make_dataset(filelist):\n",
    "    dataset_images = []\n",
    "    dataset_images_labels = []\n",
    "    for file in filelist:\n",
    "        # Leggo immagine\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE) #non è normalizzata tra 0 ed 1\n",
    "        #img = mpimg.imread(file)\n",
    "        # Aggiungo immagine aperta al dataset\n",
    "        dataset_images.append(img)\n",
    "        # Aggiungo il label dell'immagine aperta al dataset\n",
    "        dataset_images_labels.append(path_to_label(file))\n",
    "    return dataset_images, dataset_images_labels\n",
    "\n",
    "\n",
    "#SALVA DATASET\n",
    "def save_dataset(path, X, y, formato=\"jpg\"):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    \n",
    "    for i,img in enumerate(X):\n",
    "        cv2.imwrite(path + \"/\" + \"%04d\" % (i+1) + \"_\" + str(y[i]) + \".\" + formato, img)\n",
    "    print(\"dataset created\")\n",
    "\n",
    "\n",
    "        \n",
    "# SALVA SU DISCO IL DATASET DI TRAIN DOPO LA DATA AUGMENTATION\n",
    "def save_train_with_aug(path, X_train_aug, y_train_aug, formato=\"jpg\"):\n",
    "    if os.path.isdir(path + \"/train_aug\"):\n",
    "        shutil.rmtree(path + \"/train_aug\")\n",
    "    os.mkdir(path + \"/train_aug\")\n",
    "\n",
    "    for i,img in enumerate(X_train_aug):\n",
    "        cv2.imwrite(path + \"/\" + \"train_aug/\" + \"%04d\" % i + \"_\" + str(y_train_aug[i]) + \".\" + formato, img)\n",
    "                \n",
    "        \n",
    "# RITORNA LE LABELS CHE HANNO IN COMUNE I DUE DATASET\n",
    "def check_labels_in_common(labels_list1, labels_list2):\n",
    "    labels_comune = []\n",
    "    for l in labels_list1:\n",
    "        for m in labels_list2:\n",
    "            if l == m:\n",
    "                labels_comune.append(l)\n",
    "    return labels_comune\n",
    "\n",
    "\n",
    "# RITORNA IL NUMERO DELLE LABELS PER OGNI CLASSE \n",
    "def get_labels_number_in_category(labels, label_enc=None, view=False, ordina=True):\n",
    "    if labels.ndim == 2:\n",
    "        labels = categorical_to_decoded(labels, label_enc)\n",
    "        all_labels = label_enc.classes_\n",
    "    else:\n",
    "        all_labels = list(set(labels))\n",
    "    dict_labels = dict.fromkeys(set(all_labels), 0) \n",
    "    for l in labels:\n",
    "        dict_labels[l] = dict_labels[l] + 1\n",
    "    #SORTED\n",
    "    if ordina == True:\n",
    "        sorted_dict = {}\n",
    "        sorted_keys = sorted(dict_labels, key=dict_labels.get, reverse=True) \n",
    "        for w in sorted_keys:\n",
    "            sorted_dict[w] = dict_labels[w]\n",
    "        dict_labels = sorted_dict\n",
    "    #VIEW  \n",
    "    if view == True:\n",
    "        for k, v in dict_labels.items():\n",
    "            print(k, v)\n",
    "        print(\"tot labels number: \" + str(len(dict_labels)))\n",
    "    return dict_labels\n",
    "\n",
    "\n",
    "# DETTAGLI DEL DATASET\n",
    "def train_test_labels_analysis(y_train, y_test, label_enc=None):\n",
    "    dict_y_train = get_labels_number_in_category(y_train, label_enc)\n",
    "    dict_y_test = get_labels_number_in_category(y_test, label_enc)\n",
    "    n_labels_train, n_labels_test = len(dict_y_train), len(dict_y_test)\n",
    "        \n",
    "    for k, v in dict_y_train.items():\n",
    "        print(k, v , dict_y_test[k])\n",
    "    print(\"labels train number: \" + str(n_labels_train))\n",
    "    print(\"labels test number: \" + str(n_labels_test))\n",
    "\n",
    "    \n",
    "# CONVERTE DA CATEGORICAL A LISTA DECODATA\n",
    "def categorical_to_decoded(y, label_enc):\n",
    "    return label_enc.inverse_transform(np.argmax(y, axis=1))\n",
    "\n",
    "    \n",
    "# RIMUOVE DA DATASET1 LE IMMAGINI CON LABEL CON CONTENUTE IN DATASET2\n",
    "def adjust_dataset1_to_dataset2(dataset_images_1, dataset_labels_1, dataset_images_2, dataset_labels_2):\n",
    "    diff_labels_2 = list(set(dataset_labels_2))  # prendo tutte le label diverse di dataset2\n",
    "    diff_labels_1 = list(set(dataset_labels_1))\n",
    "    labels_comune = check_labels_in_common(dataset_labels_2, dataset_labels_1)\n",
    "    intersect = [l for l in diff_labels_1 if l not in labels_comune]  #label rimanenti in dataset2\n",
    "    dataset_images_1 = [img for i,img in enumerate(dataset_images_1) if dataset_labels_1[i] not in intersect]\n",
    "    dataset_labels_1 = [label for i,label in enumerate(dataset_labels_1) if dataset_labels_1[i] not in intersect]\n",
    "    return dataset_images_1, dataset_labels_1\n",
    "\n",
    "\n",
    "# AGGIUNGE DIMENSIONE EXTRA A IMAGE E LABEL\n",
    "def add_extra_dim(imgs, labels, n_classes):\n",
    "    if imgs.ndim == 3:\n",
    "        imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2], 1))\n",
    "    else:\n",
    "        print(\"error: imgs dataset dimension is \" +str(imgs.ndim)+\" instead 3\")\n",
    "        return\n",
    "    if labels.ndim == 1:\n",
    "        labels = to_categorical(labels, num_classes=n_classes)\n",
    "    else:\n",
    "        print(\"error: labels dataset dimension is \" +str(labels.ndim)+\" instead 1\")\n",
    "        return\n",
    "    return imgs, labels\n",
    "\n",
    "        \n",
    "# AUMENTO DEL DATASET\n",
    "def data_augmentation(datagen, images, labels, n_aug):\n",
    "    it = datagen.flow(images, labels, batch_size=1)\n",
    "    for i in range(0, n_aug):\n",
    "        next_it = next(it)\n",
    "        image = next_it[0]\n",
    "        label = next_it[1]\n",
    "        images = np.append(images, image, axis= 0)\n",
    "        labels = np.append(labels, label, axis=0)\n",
    "        #print(\"augmentation of \" + str(i+1) + \" data\")\n",
    "        #plt.imshow(image, cmap=\"gray\")\n",
    "        #plt.show()\n",
    "    return images, labels\n",
    "\n",
    "         \n",
    "        \n",
    "# PLOT TRAIN E VALIDATION LOSS E ACCURACY        \n",
    "def plot_train_validation_loss_accuracy(history):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_prediction_data(predictions, X_test, y_test, label_enc, summary=False, details=False, \n",
    "                        plot=(None,0,None), y_train=None):\n",
    "    # plot = (plot_type, plot_n)\n",
    "    # plot_type  0 - only corrected pred\n",
    "    #            1 - only wrong pred\n",
    "    #            2 - corrected + wrong pred\n",
    "    #            None\n",
    "    # plot_n     int - number of images to plot\n",
    "    #            \"all\" plot all images\n",
    "    # only_label_to_print     \"S29\" - label of images to plot\n",
    "    #            None\n",
    "    if plot[0] is not None:\n",
    "        plot_type = plot[0]\n",
    "    else:\n",
    "        plot_type = None\n",
    "    plot_n = plot[1]\n",
    "    only_label_to_print = plot[2]\n",
    "    pred_corr = 0\n",
    "    pred_wrong = 0\n",
    "    plot_counter = 0\n",
    "    y_test_decoded = label_enc.inverse_transform(np.argmax(y_test, axis=1))\n",
    "    d_pred_corr = dict.fromkeys(set(y_test_decoded), 0)\n",
    "    d_tot_label = dict.fromkeys(set(y_test_decoded), 0)\n",
    "    if y_train is not None:\n",
    "        d_train_label = get_labels_number_in_category(y_train, label_enc)\n",
    "        \n",
    "    for i,prediction in enumerate(predictions):\n",
    "        p = np.argmax(prediction)\n",
    "        true_label_enc = np.argmax(y_test[i])\n",
    "        true_label = label_enc.inverse_transform([true_label_enc])[0]\n",
    "        d_tot_label[true_label] = d_tot_label[true_label] +1\n",
    "        \n",
    "        if plot_n is \"all\":\n",
    "            plot_n = len(predictions)\n",
    "        \n",
    "        if p == true_label_enc:\n",
    "            pred_corr = pred_corr + 1\n",
    "            d_pred_corr[true_label] = d_pred_corr[true_label] +1\n",
    "            if(summary is True):\n",
    "                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" corrected prediction  \" + \"prediction = \"+ str(p) +\"  true_label_enc = \"+ str(true_label_enc))\n",
    "            \n",
    "            if plot_type is 0 or plot_type is 2 :  \n",
    "                if plot_counter < plot_n:\n",
    "                    if only_label_to_print is not None:\n",
    "                        if str(true_label) == only_label_to_print:\n",
    "                            plt.figure(i)\n",
    "                            plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"° corrected - \" +\"label \"+ str(true_label))\n",
    "                            plot_counter = plot_counter + 1\n",
    "                    else:        \n",
    "                        plt.figure(i)\n",
    "                        plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"° corrected - \" +\"label \"+ str(true_label))\n",
    "                        plot_counter = plot_counter + 1\n",
    "                    \n",
    "        else:\n",
    "            pred_wrong = pred_wrong + 1\n",
    "            if summary is True:\n",
    "                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" wrong prediction\")\n",
    "            if plot_type is 1 or plot_type is 2:\n",
    "                if plot_counter < plot_n:   \n",
    "                    if only_label_to_print is not None:\n",
    "                        if str(true_label) == only_label_to_print:\n",
    "                            plt.figure(i)\n",
    "                            plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"° wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n",
    "                            plot_counter = plot_counter + 1\n",
    "                    else:\n",
    "                        plt.figure(i)\n",
    "                        plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"° wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n",
    "                        plot_counter = plot_counter + 1\n",
    "    \n",
    "    if summary is True:\n",
    "        print(\"-------\")\n",
    "        print(\"Corrected predictions: \" + str(pred_corr) + \"/\" + str(len(predictions)) )\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    if details is True:\n",
    "        if y_train is None:\n",
    "            for key in d_tot_label:\n",
    "                print(str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )\n",
    "        else:\n",
    "            for key in d_train_label:\n",
    "                if key in d_tot_label:\n",
    "                    print(str(d_train_label[key]) + \" \"+ str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )    \n",
    "                else:\n",
    "                    print(str(d_train_label[key]) + \" No images in test of label \"+ str(key))\n",
    "        print(\"-------\")\n",
    "        print(\"Correct prediction: \" +str(sum(d_pred_corr.values()))+\"/\"+str(sum(d_tot_label.values())))\n",
    "  \n",
    "    if plot_type is 0 or plot_type is 1 or plot_type is 2 :\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "\n",
    "    initial_lr = 0.001\n",
    "    if epoch<=30:\n",
    "        lr = initial_lr\n",
    "    elif epoch<=80:\n",
    "        lr = initial_lr/10\n",
    "    elif epoch<=120:\n",
    "        lr = initial_lr/20 \n",
    "    else:\n",
    "        lr = initial_lr/20 \n",
    "\n",
    "    log('current learning rate is %2.8f' %lr)\n",
    "    return lr\n",
    "\n",
    "def log(*args,**kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPl2q9w69gzCNAiAh6we+kI",
   "collapsed_sections": [],
   "name": "util.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
