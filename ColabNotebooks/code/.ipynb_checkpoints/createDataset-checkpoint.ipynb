{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3hF9LcDNYWC"
   },
   "outputs": [],
   "source": [
    "# ----------- README for the Datasets ----------------\n",
    "#  Dataset_oland ha 4210 immagini e 172 diverse labels con dim 50x75[w,h] in grayscale\n",
    "#  Dataset_nostro ha 1310 immagini e 48 diverse labels con dim 50x75[w,h] in grayscale\n",
    "#  I due dataset hanno in comune 40 label diverse e utilizzando solo queste otteniamo\n",
    "#       - Dataset_oland_adjust ha 3101 immagini con 40 labels diverse\n",
    "#       - Dataset_nostro_adjust ha 1207 immagini con 40 labels diverse\n",
    "#       - Le 8 labels di Dataset_nostro che non possono essere classificate sono: A1,A40,Aa1,D55,U6,W3,Y4,Z2\n",
    "#       => tot_img = 4308 , tot_classes = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "oF5J9vHiMTno"
   },
   "outputs": [],
   "source": [
    "# LOCALE\n",
    "\n",
    "%run util.ipynb\n",
    "\n",
    "# path_tot = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/tot\"\n",
    "# path_train = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/train\"\n",
    "# path_testA = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/testA\"\n",
    "# path_testB = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/testB\"\n",
    "# path_train_aug = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/train_aug\"\n",
    "\n",
    "#path_train_flip = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/train_flip\"\n",
    "#path_test_flip = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/test_flip\"\n",
    "#path_train_flip_aug = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/train_flip_aug\"\n",
    "#path_test_flip_aug = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/test_flip_aug\"\n",
    "\n",
    "#path_train_Kfold_flip_aug = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/K-fold/1/train_HF_aug\"\n",
    "#path_val_Kfold_flip = \"/Users/marco/Desktop/tesi/campioni/datasets(200x200)/K-fold/1/val_HF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "BjNnMksPoH_8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione array di immagini oland dopo il reshape: (3102, 200, 200, 1)\n",
      "Dimensione array labels oland: (3102, 40)\n",
      "Dimensione array di immagini dopo il reshape: (1206, 200, 200, 1)\n",
      "Dimensione array labels: (1206, 40)\n",
      "dataset created\n"
     ]
    }
   ],
   "source": [
    "# INITIAL JOIN DATASET(OLAND+OURS) E SALVATAGGIO DEL TRAIN E DEL TEST\n",
    "  \n",
    "# dataset path\n",
    "path_oland = \"/Users/marco/Desktop/tesi/campioni/campioni_processed/Oland_campioni(200x200)\"\n",
    "path = '/Users/marco/Desktop/tesi/campioni/campioni_processed/CampioniL_V3(200x200)'\n",
    "\n",
    "# creo i dataset\n",
    "dataset_images_oland, dataset_labels_oland = load_dataset(path_oland, \"png\")\n",
    "dataset_images, dataset_labels = load_dataset(path, \"jpg\")\n",
    "\n",
    "# tolgo dal dataset nostro le immagini con etichette che non sono presenti nel dataset degli olandese\n",
    "dataset_images, dataset_labels = adjust_dataset1_to_dataset2(dataset_images, dataset_labels,\n",
    "                                                          dataset_images_oland, dataset_labels_oland)\n",
    "\n",
    "# tolgo dal dataset olandese tutte le immagini che non sono presenti negli olandesi(addestro solo per quelli che mi servono)\n",
    "dataset_images_oland, dataset_labels_oland = adjust_dataset1_to_dataset2(dataset_images_oland, dataset_labels_oland,\n",
    "                                                          dataset_images, dataset_labels)\n",
    "\n",
    "\n",
    "# encoding delle label  # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(dataset_labels_oland)  \n",
    "dataset_labels_oland_encoded = label_enc.transform(dataset_labels_oland) # trasforma le label da caratteri a numeri\n",
    "dataset_labels_encoded = label_enc.transform(dataset_labels) # trasforma le label da caratteri a numeri\n",
    "n_classes = len(list(label_enc.classes_))\n",
    "\n",
    "# trasformo da list a np array\n",
    "dataset_images_oland = np.asarray(dataset_images_oland)\n",
    "dataset_images = np.asarray(dataset_images)\n",
    "\n",
    "# Aggiungo una extra-dimensione alle immagini e hot-encoding dei labels perche' e' come le vuole in input il modello cnn\n",
    "dataset_images_oland, dataset_labels_oland_encoded = add_extra_dim(dataset_images_oland, dataset_labels_oland_encoded, n_classes)\n",
    "dataset_images, dataset_labels_encoded = add_extra_dim(dataset_images, dataset_labels_encoded, n_classes)\n",
    "\n",
    "print('Dimensione array di immagini oland dopo il reshape:',np.shape(dataset_images_oland))\n",
    "print('Dimensione array labels oland:',np.shape(dataset_labels_oland_encoded))\n",
    "print('Dimensione array di immagini dopo il reshape:',np.shape(dataset_images))\n",
    "print('Dimensione array labels:',np.shape(dataset_labels_encoded))\n",
    "\n",
    "\n",
    "# SCELTA DEL TRAIN E DEL TEST\n",
    "\n",
    "# Splitting del dataset in train and test\n",
    "#X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(dataset_images_oland, dataset_labels_oland_encoded, test_size=0.15, stratify=dataset_labels_oland_encoded, random_state=123)\n",
    "#X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(dataset_images, dataset_labels_encoded, test_size=0.15, stratify=dataset_labels_encoded, random_state=123)\n",
    "# Unione dataset\n",
    "#X_train = np.append(X_train_A, X_train_B, axis= 0)\n",
    "#y_train = np.append(y_train_A, y_train_B, axis= 0)\n",
    "#X_test = np.append(X_test_A, X_test_B, axis= 0)\n",
    "#y_test = np.append(y_test_A, y_test_B, axis= 0)\n",
    "#X_tot = np.append(X_train, X_test, axis= 0)\n",
    "#y_tot = np.append(y_train, y_test, axis= 0)\n",
    "\n",
    "\n",
    "# SCELTA DEL TRAIN E DEL TEST CON DIVISIONE ANCHE DEL VALIDATION\n",
    "X_train_A, X_val_test_A, y_train_A, y_val_test_A = train_test_split(dataset_images_oland, dataset_labels_oland_encoded, test_size=0.3)\n",
    "X_train_B, X_val_test_B, y_train_B, y_val_test_B = train_test_split(dataset_images, dataset_labels_encoded, test_size=0.3, random_state=123)\n",
    "X_val_A, X_test_A, y_val_A, y_test_A = train_test_split(X_val_test_A, y_val_test_A, test_size=0.5, random_state=123)\n",
    "X_val_B, X_test_B, y_val_B, y_test_B = train_test_split(X_val_test_B, y_val_test_B, test_size=0.5, random_state=123)\n",
    "# Unione dataset\n",
    "X_train = np.append(X_train_A, X_train_B, axis= 0)\n",
    "y_train = np.append(y_train_A, y_train_B, axis= 0)\n",
    "X_val = np.append(X_val_A, X_val_B, axis= 0)\n",
    "y_val = np.append(y_val_A, y_val_B, axis= 0)\n",
    "X_test = np.append(X_test_A, X_test_B, axis= 0)\n",
    "y_test = np.append(y_test_A, y_test_B, axis= 0)\n",
    "#print('Train images and labels: ',X_train.shape, y_train.shape)\n",
    "#print('Val images and labels of oland dataset: ',X_val_A.shape, y_val_A.shape)\n",
    "#print('Val images and labels of ours dataset: ',X_val_B.shape, y_val_B.shape)\n",
    "#print('Test images and labels of oland dataset: ',X_test_A.shape, y_test_A.shape)\n",
    "#print('Test images and labels of ours dataset: ',X_test_B.shape, y_test_B.shape)\n",
    "\n",
    "\n",
    "#SAVE DATASETS\n",
    "#save_dataset(\"/Users/marco/Desktop/trainA\", X_train_A, categorical_to_decoded(y_train_A, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/trainB\", X_train_B, categorical_to_decoded(y_train_B, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/testA\", X_test_A, categorical_to_decoded(y_test_A, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/testB\", X_test_B, categorical_to_decoded(y_test_B, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/train\", X_train, categorical_to_decoded(y_train, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/val\", X_val, categorical_to_decoded(y_val, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/test\", X_test, categorical_to_decoded(y_test, label_enc))\n",
    "#save_dataset(\"/Users/marco/Desktop/tot\", X_tot, categorical_to_decoded(y_tot, label_enc))\n",
    "\n",
    "#PER CREARE UN DATASET FLIPPATO\n",
    "#save_dataset(\"/Users/marco/Desktop/test_flip\", X_test, categorical_to_decoded(y_test, label_enc), horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7058,
     "status": "ok",
     "timestamp": 1617370866345,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "CdVz5sVbNYWF",
    "outputId": "6c390559-bcbf-42ae-b0c2-e3c217115675",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tot:  (4309, 100, 100, 1) (4309, 40)\n",
      "Train:  (3014, 100, 100, 1) (3014, 40)\n",
      "Test:  (647, 100, 100, 1) (647, 40)\n",
      "Val:  (647, 100, 100, 1) (647, 40)\n"
     ]
    }
   ],
   "source": [
    "# DATASET PREPARATION\n",
    "\n",
    "path_tot = \"/Users/marco/Desktop/new/tot\"\n",
    "path_train = \"/Users/marco/Desktop/new/train\"\n",
    "path_val = \"/Users/marco/Desktop/new/val\"\n",
    "path_test = \"/Users/marco/Desktop/new/test\"\n",
    "    \n",
    "# loading datasets from disco\n",
    "X_tot, y_tot = load_dataset(path_tot, \"jpg\")\n",
    "X_train, y_train = load_dataset(path_train, \"jpg\")\n",
    "X_test, y_test = load_dataset(path_test, \"jpg\")\n",
    "X_val, y_val = load_dataset(path_val, \"jpg\")\n",
    "\n",
    "\n",
    "# encoding delle label  # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(y_tot) \n",
    "y_tot = label_enc.transform(y_tot) # trasforma le label da caratteri a numeri\n",
    "y_train = label_enc.transform(y_train) # trasforma le label da caratteri a numeri\n",
    "y_test = label_enc.transform(y_test) # trasforma le label da caratteri a numeri\n",
    "y_val = label_enc.transform(y_val) # trasforma le label da caratteri a numeri\n",
    "print()\n",
    "\n",
    "n_classes = len(list(label_enc.classes_))\n",
    "\n",
    "# trasformo da list a np array\n",
    "X_tot = np.asarray(X_tot)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)\n",
    "\n",
    "# Aggiungo una extra-dimensione alle immagini e faccio Hot-encoding dei labels perche' e' come le vuole in input il modello cnn\n",
    "X_tot, y_tot = add_extra_dim(X_tot, y_tot, n_classes)\n",
    "X_train, y_train = add_extra_dim(X_train, y_train, n_classes)\n",
    "X_test, y_test = add_extra_dim(X_test, y_test, n_classes)\n",
    "X_val, y_val = add_extra_dim(X_val, y_val, n_classes)\n",
    "\n",
    "print('Tot: ',X_tot.shape, y_tot.shape)\n",
    "print('Train: ',X_train.shape, y_train.shape)\n",
    "print('Test: ',X_test.shape, y_test.shape)\n",
    "print('Val: ',X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7Ksc0SbhDID",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATASET INFO\n",
    "#train_test_labels_analysis(y_test_A, y_test_B, label_enc)\n",
    "#get_labels_number_in_category(dataset_labels_aug, label_enc, view=True)\n",
    "get_labels_number_in_category(y_val, label_enc, view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot:  (4309, 100, 100) (4309,)\n"
     ]
    }
   ],
   "source": [
    "#X_tot, y_tot = remove_extra_dim(X_tot, y_tot, label_enc)\n",
    "#print('Tot: ',X_tot.shape, y_tot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpMtW3QsEJ3e"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPhXcI9zEqIG"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20, # rotation\n",
    "    width_shift_range=0.1, # horizontal shift\n",
    "    height_shift_range=0.1, # vertical shift\n",
    "    zoom_range=0.05, # zoom\n",
    "    horizontal_flip=True, # horizontal flip\n",
    "    brightness_range=[0.2,1.2]) # brightness\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='/Users/marco/Desktop/prova',\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    next_it = next(train_generator)\n",
    "    image = next_it[0]\n",
    "    label = next_it[1]\n",
    "    #images = np.append(images, image, axis= 0)\n",
    "    #labels = np.append(labels, label, axis=0)\n",
    "    #print(\"augmentation of \" + str(i+1) + \" data\")\n",
    "    plt.imshow(image[0], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "GmP2-WeUoIAA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "S34 4 12\n",
      "M23 7 9\n",
      "D58 8 8\n",
      "V31 23 0\n",
      "D36 16 0\n",
      "O49 2 14\n",
      "I10 16 0\n",
      "D4 10 6\n",
      "V30 4 12\n",
      "I9 37 0\n",
      "Y5 5 11\n",
      "D46 10 6\n",
      "O34 9 7\n",
      "D2 6 10\n",
      "O1 5 11\n",
      "F35 1 15\n",
      "W11 2 14\n",
      "N35 76 0\n",
      "Q1 8 8\n",
      "G17 27 0\n",
      "S29 58 0\n",
      "Y1 2 14\n",
      "F31 3 13\n",
      "O4 5 11\n",
      "R8 15 1\n",
      "E23 1 15\n",
      "D21 39 0\n",
      "W24 5 11\n",
      "Q3 20 0\n",
      "V28 7 9\n",
      "M17 64 0\n",
      "E34 22 0\n",
      "U7 1 15\n",
      "V13 9 7\n",
      "X1 41 0\n",
      "G43 47 0\n",
      "R4 5 11\n",
      "X8 3 13\n",
      "G1 11 5\n",
      "Z1 13 3\n",
      "dataset created\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE DATASET(train(with_aug))\n",
    "\n",
    "def aug_dataset(X_input, y_input, path_to_save, save=False, horizontal_flip=False):\n",
    "    \n",
    "    #calcolo il valore medio dei campioni del dataset\n",
    "    dic = get_labels_number_in_category(y_input, label_enc, view=False)\n",
    "    mean = int(round(np.mean([int(i) for i in dic.values()])))\n",
    "    print(mean)\n",
    "    \n",
    "    X, y = remove_extra_dim(X_input, y_input, label_enc)\n",
    "\n",
    "    \n",
    "    #DATA AUGMENTATION\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=2, # rotation\n",
    "        width_shift_range=0.1, # horizontal shift\n",
    "        height_shift_range=0.1, # vertical shift\n",
    "        zoom_range=0.05, # zoom\n",
    "        horizontal_flip=False, # horizontal flip\n",
    "        brightness_range=[0.2,1.2]) # brightness\n",
    "    #datagen.fit(X_train)\n",
    "\n",
    "    \n",
    "    dataset_images_aug, dataset_labels_aug = [],[]\n",
    "    all_labels = list(set(y))\n",
    "    for index_l,l in enumerate(all_labels):\n",
    "        img_one_class = []\n",
    "        for i,label in enumerate(y):\n",
    "            if label == l:\n",
    "                img_one_class.append(X[i])\n",
    "        img_one_class = np.asarray(img_one_class)\n",
    "        label_one_class = [l for i in range(img_one_class.shape[0])]\n",
    "        label_one_class = label_enc.transform(label_one_class)\n",
    "        label_one_class = np.asarray(label_one_class)\n",
    "        img_one_class, label_one_class = add_extra_dim(img_one_class, label_one_class, n_classes)\n",
    "        \n",
    "        if img_one_class.shape[0] < mean:\n",
    "            n_aug = mean - img_one_class.shape[0]\n",
    "        else:\n",
    "            n_aug = 0\n",
    "    \n",
    "        #if img_one_class.shape[0] > 10:\n",
    "        #    n_aug = int(X.shape[0]/(img_one_class.shape[0] * 100))\n",
    "        #else:\n",
    "        #    n_aug = int(X.shape[0]/(img_one_class.shape[0] * 100))\n",
    "        print(label_enc.inverse_transform(np.argmax(label_one_class, axis=1))[0], img_one_class.shape[0], n_aug)\n",
    "        img_one_class, label_one_class = data_augmentation(datagen, img_one_class, label_one_class, n_aug)\n",
    "        \n",
    "\n",
    "        if index_l == 0:\n",
    "            dataset_images_aug = img_one_class\n",
    "            dataset_labels_aug = label_one_class\n",
    "        else:\n",
    "            dataset_images_aug = np.append(dataset_images_aug, img_one_class, axis= 0)\n",
    "            dataset_labels_aug = np.append(dataset_labels_aug, label_one_class, axis= 0)\n",
    "\n",
    "    if save==True:\n",
    "        save_dataset(path_to_save, dataset_images_aug, categorical_to_decoded(dataset_labels_aug, label_enc), horizontal_flip=horizontal_flip)\n",
    "    \n",
    "    return dataset_images_aug, dataset_labels_aug\n",
    "\n",
    "\n",
    "\n",
    "X_aug, y_aug = aug_dataset(X_test, y_test, path_to_save=\"/Users/marco/Desktop/new/test_aug\"\n",
    "                           , save=True, horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gehyT3LEGsz",
    "outputId": "ce6df4a2-e538-49fd-d095-d84dad4d05cc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Dimensione array di immagini dopo data aug:',np.shape(X_train_flip))\n",
    "print('Dimensione array labels dopo il data aug:',np.shape(y_train_flip))  \n",
    "get_labels_number_in_category(y_train_flip, label_enc, view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8VP4h0zdw6Q"
   },
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnRW_dlGd9wF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "for train_index, test_index in skf.split(X_tot, categorical_to_decoded(y_tot, label_enc)):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_tot[train_index], X_tot[test_index]\n",
    "    y_train, y_test = y_tot[train_index], y_tot[test_index]\n",
    "    \n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/train\", X_train, categorical_to_decoded(y_train, label_enc))\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/train_HF\", X_train, categorical_to_decoded(y_train, label_enc), horizontal_flip=True)\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/test\", X_test, categorical_to_decoded(y_test, label_enc))\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/test_HF\", X_test, categorical_to_decoded(y_test, label_enc), horizontal_flip=True)\n",
    "    \n",
    "    print(str(count), X_train.shape, X_test.shape)\n",
    "    print(str(count), y_train.shape, y_test.shape)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "for train_index, test_index in skf.split(X_tot, categorical_to_decoded(y_tot, label_enc)):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_tot[train_index], X_tot[test_index]\n",
    "    y_train, y_test = y_tot[train_index], y_tot[test_index]\n",
    "    \n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/train\", X_train, categorical_to_decoded(y_train, label_enc))\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/train_HF\", X_train, categorical_to_decoded(y_train, label_enc), horizontal_flip=True)\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/test\", X_test, categorical_to_decoded(y_test, label_enc))\n",
    "    save_dataset(\"/Users/marco/Desktop/K-fold/\"+str(count)+\"/test_HF\", X_test, categorical_to_decoded(y_test, label_enc), horizontal_flip=True)\n",
    "    \n",
    "    print(str(count), X_train.shape, X_test.shape)\n",
    "    print(str(count), y_train.shape, y_test.shape)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34afdsCtSGGx"
   },
   "source": [
    "# Tranfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHSDPK4G8Usy"
   },
   "outputs": [],
   "source": [
    "# MODEL WITH TRANSFER LEARNING\n",
    "base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\", \n",
    "                                    input_shape=(np.shape(X_train)[1], np.shape(X_train)[2], 3)) \n",
    "#model.summary()\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(np.shape(X_train)[1], np.shape(X_train)[2], 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(n_classes)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# COMPILE\n",
    "model.compile(optimizer=Adam(0.001), \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# IMAGES GRAYSCALE TO \"RGB\"\n",
    "X_train = np.repeat(X_train, 3, -1)\n",
    "X_test_A = np.repeat(X_test_A, 3, -1)\n",
    "X_test_B = np.repeat(X_test_B, 3, -1)\n",
    "\n",
    "\n",
    "# NETWORK TRAINING\n",
    "#checkpoint = ModelCheckpoint(checkpoint_filepath + \"/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\" ,\n",
    "#                             save_weights_only=True,\n",
    "#                             monitor='val_accuracy',\n",
    "#                             mode='max',\n",
    "#                             save_best_only=True,\n",
    "#                             verbose=1,\n",
    "#                             save_freq='epoch')\n",
    "#history = model.fit(X_train, y_train,\n",
    "#                    validation_split=0.17, \n",
    "#                    epochs=300, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxuopOoGNYWJ"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1617371970126,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "4zz8lvJC-PTJ"
   },
   "outputs": [],
   "source": [
    " def build_model():\n",
    "    # MODEL\n",
    "    model = get_InceptionV3(shape=(np.shape(X_train_flip_aug)[1], np.shape(X_train_flip_aug)[2], 1), n_classes=n_classes)\n",
    "    #model.summary()\n",
    "\n",
    "    top3 = tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")\n",
    "    top5 = tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")\n",
    "    model.compile(optimizer=Adam(), \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy', top3, top5])\n",
    "\n",
    "    #model.compile(optimizer=SGD(lr=0.01, momentum=0.9), \n",
    "    #                  loss='categorical_crossentropy', \n",
    "    #                  metrics=['accuracy'])\n",
    "\n",
    "    #print(len(model.layers))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eArOmpkwRR-Q"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFuR9er9cQYd",
    "outputId": "a855b86b-90d5-4684-9ad7-8cc93759f85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "current learning rate is 0.00100000\n",
      "207/207 [==============================] - 54s 218ms/step - loss: 2.7294 - accuracy: 0.3421 - top3: 0.5418 - top5: 0.6313 - val_loss: 5.4401 - val_accuracy: 0.3233 - val_top3: 0.5240 - val_top5: 0.6201\n",
      "Epoch 2/100\n",
      "current learning rate is 0.00095484\n",
      "207/207 [==============================] - 40s 195ms/step - loss: 1.0682 - accuracy: 0.6747 - top3: 0.8639 - top5: 0.9214 - val_loss: 3.1277 - val_accuracy: 0.3242 - val_top3: 0.6235 - val_top5: 0.7410\n",
      "Epoch 3/100\n",
      "current learning rate is 0.00091172\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.6722 - accuracy: 0.7863 - top3: 0.9399 - top5: 0.9684 - val_loss: 0.9925 - val_accuracy: 0.7110 - val_top3: 0.8834 - val_top5: 0.9271\n",
      "Epoch 4/100\n",
      "current learning rate is 0.00087055\n",
      "207/207 [==============================] - 40s 196ms/step - loss: 0.4280 - accuracy: 0.8615 - top3: 0.9696 - top5: 0.9865 - val_loss: 1.0642 - val_accuracy: 0.7684 - val_top3: 0.9305 - val_top5: 0.9631\n",
      "Epoch 5/100\n",
      "current learning rate is 0.00083124\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.3347 - accuracy: 0.8947 - top3: 0.9815 - top5: 0.9923 - val_loss: 1.5031 - val_accuracy: 0.6372 - val_top3: 0.8388 - val_top5: 0.9074\n",
      "Epoch 6/100\n",
      "current learning rate is 0.00079370\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.2296 - accuracy: 0.9250 - top3: 0.9904 - top5: 0.9980 - val_loss: 0.3229 - val_accuracy: 0.9039 - val_top3: 0.9726 - val_top5: 0.9837\n",
      "Epoch 7/100\n",
      "current learning rate is 0.00075786\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.1626 - accuracy: 0.9460 - top3: 0.9950 - top5: 0.9988 - val_loss: 0.4365 - val_accuracy: 0.8628 - val_top3: 0.9743 - val_top5: 0.9863\n",
      "Epoch 8/100\n",
      "current learning rate is 0.00072363\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.1815 - accuracy: 0.9444 - top3: 0.9907 - top5: 0.9953 - val_loss: 0.3544 - val_accuracy: 0.8851 - val_top3: 0.9837 - val_top5: 0.9914\n",
      "Epoch 9/100\n",
      "current learning rate is 0.00069096\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.1128 - accuracy: 0.9617 - top3: 0.9966 - top5: 0.9994 - val_loss: 0.2849 - val_accuracy: 0.9091 - val_top3: 0.9811 - val_top5: 0.9906\n",
      "Epoch 10/100\n",
      "current learning rate is 0.00065975\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.1027 - accuracy: 0.9636 - top3: 0.9976 - top5: 0.9997 - val_loss: 0.1384 - val_accuracy: 0.9528 - val_top3: 0.9940 - val_top5: 0.9983\n",
      "Epoch 11/100\n",
      "current learning rate is 0.00062996\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0744 - accuracy: 0.9741 - top3: 0.9985 - top5: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.7796 - val_top3: 0.9245 - val_top5: 0.9597\n",
      "Epoch 12/100\n",
      "current learning rate is 0.00060151\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0703 - accuracy: 0.9758 - top3: 0.9991 - top5: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9554 - val_top3: 0.9923 - val_top5: 0.9991\n",
      "Epoch 13/100\n",
      "current learning rate is 0.00057435\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0335 - accuracy: 0.9893 - top3: 0.9994 - top5: 0.9999 - val_loss: 0.1672 - val_accuracy: 0.9477 - val_top3: 0.9914 - val_top5: 0.9966\n",
      "Epoch 14/100\n",
      "current learning rate is 0.00054841\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0289 - accuracy: 0.9904 - top3: 0.9987 - top5: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9434 - val_top3: 0.9871 - val_top5: 0.9966\n",
      "Epoch 15/100\n",
      "current learning rate is 0.00052365\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0556 - accuracy: 0.9828 - top3: 0.9994 - top5: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9245 - val_top3: 0.9846 - val_top5: 0.9931\n",
      "Epoch 16/100\n",
      "current learning rate is 0.00050000\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0568 - accuracy: 0.9810 - top3: 0.9993 - top5: 0.9999 - val_loss: 0.1349 - val_accuracy: 0.9605 - val_top3: 0.9940 - val_top5: 0.9957\n",
      "Epoch 17/100\n",
      "current learning rate is 0.00047742\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0223 - accuracy: 0.9944 - top3: 0.9998 - top5: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9614 - val_top3: 0.9957 - val_top5: 0.9983\n",
      "Epoch 18/100\n",
      "current learning rate is 0.00045586\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0140 - accuracy: 0.9955 - top3: 0.9998 - top5: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9511 - val_top3: 0.9914 - val_top5: 0.9966\n",
      "Epoch 19/100\n",
      "current learning rate is 0.00043528\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0207 - accuracy: 0.9941 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9520 - val_top3: 0.9923 - val_top5: 0.9966\n",
      "Epoch 20/100\n",
      "current learning rate is 0.00041562\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0355 - accuracy: 0.9887 - top3: 0.9989 - top5: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9580 - val_top3: 0.9949 - val_top5: 0.9983\n",
      "Epoch 21/100\n",
      "current learning rate is 0.00039685\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0336 - accuracy: 0.9907 - top3: 0.9999 - top5: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9614 - val_top3: 0.9940 - val_top5: 0.9966\n",
      "Epoch 22/100\n",
      "current learning rate is 0.00037893\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0246 - accuracy: 0.9931 - top3: 0.9995 - top5: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9666 - val_top3: 0.9949 - val_top5: 0.9983\n",
      "Epoch 23/100\n",
      "current learning rate is 0.00036182\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0176 - accuracy: 0.9944 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9734 - val_top3: 0.9991 - val_top5: 1.0000\n",
      "Epoch 24/100\n",
      "current learning rate is 0.00034548\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0135 - accuracy: 0.9956 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9537 - val_top3: 0.9983 - val_top5: 1.0000\n",
      "Epoch 25/100\n",
      "current learning rate is 0.00032988\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0092 - accuracy: 0.9968 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9631 - val_top3: 0.9966 - val_top5: 1.0000\n",
      "Epoch 26/100\n",
      "current learning rate is 0.00031498\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0193 - accuracy: 0.9932 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9828 - val_top3: 0.9957 - val_top5: 1.0000\n",
      "Epoch 27/100\n",
      "current learning rate is 0.00030076\n",
      "207/207 [==============================] - 41s 196ms/step - loss: 0.0105 - accuracy: 0.9961 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9760 - val_top3: 0.9974 - val_top5: 0.9983\n",
      "Epoch 28/100\n",
      "current learning rate is 0.00028717\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.0041 - accuracy: 0.9989 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9837 - val_top3: 0.9983 - val_top5: 1.0000\n",
      "Epoch 29/100\n",
      "current learning rate is 0.00027421\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.0027 - accuracy: 0.9988 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9871 - val_top3: 0.9983 - val_top5: 1.0000\n",
      "Epoch 30/100\n",
      "current learning rate is 0.00026182\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.0025 - accuracy: 0.9995 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9889 - val_top3: 0.9974 - val_top5: 1.0000\n",
      "Epoch 31/100\n",
      "current learning rate is 0.00025000\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 3.7962e-04 - accuracy: 1.0000 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9889 - val_top3: 0.9983 - val_top5: 1.0000\n",
      "Epoch 32/100\n",
      "current learning rate is 0.00023871\n",
      "207/207 [==============================] - 41s 197ms/step - loss: 0.0015 - accuracy: 0.9997 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9906 - val_top3: 0.9974 - val_top5: 1.0000\n",
      "Epoch 33/100\n",
      "current learning rate is 0.00022793\n",
      "207/207 [==============================] - 41s 198ms/step - loss: 8.9109e-04 - accuracy: 0.9998 - top3: 1.0000 - top5: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9880 - val_top3: 0.9991 - val_top5: 1.0000\n",
      "Epoch 34/100\n",
      "current learning rate is 0.00021764\n",
      "184/207 [=========================>....] - ETA: 4s - loss: 0.0031 - accuracy: 0.9994 - top3: 1.0000 - top5: 1.0000"
     ]
    }
   ],
   "source": [
    "# NETWORK TRAINING\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "log_dir = log_filepath + \"/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath + \"/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\" ,\n",
    "                             save_weights_only=True,\n",
    "                             monitor='val_accuracy',\n",
    "                             mode='max',\n",
    "                             save_best_only=False,\n",
    "                             verbose=1,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "history = model.fit(X_train_flip_aug, y_train_flip_aug,\n",
    "                    validation_split=0.15, \n",
    "                    epochs=100, shuffle=True, callbacks=[lr_scheduler])\n",
    "\n",
    "from google.colab import files\n",
    "np.save('/content/drive/MyDrive/ColabNotebooks/history_train.npy',history.history)\n",
    "# files.download('/content/drive/MyDrive/ColabNotebooks/history_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IeCcaIhxwQd"
   },
   "outputs": [],
   "source": [
    "# NETWORK TRAINING K-FOLD\n",
    "log_dir = log_filepath + \"/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath + \"/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\" ,\n",
    "                             save_weights_only=True,\n",
    "                             monitor='val_accuracy',\n",
    "                             mode='max',\n",
    "                             save_best_only=False,\n",
    "                             verbose=1,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "history = model.fit(X_train_Kfold_flip_aug, y_train_Kfold_flip_aug,\n",
    "                    validation_data=(X_val_Kfold_flip, y_val_Kfold_flip), \n",
    "                    epochs=100, shuffle=True, callbacks=[tensorboard_callback, lr_scheduler])\n",
    "\n",
    "from google.colab import files\n",
    "np.save('/content/drive/MyDrive/ColabNotebooks/history_train.npy',history.history)\n",
    "#files.download('/content/drive/MyDrive/ColabNotebooks/history_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2903,
     "status": "ok",
     "timestamp": 1617371950198,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "VXgkaVX71MxC",
    "outputId": "195166f0-3b7b-498a-8173-f2463d120590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 106ms/step - loss: 1.1383 - accuracy: 0.6373 - top3: 0.9059 - top5: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.138269066810608, 0.6373456716537476, 0.9058641791343689, 0.9583333134651184]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lL2coJiydlJ7"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/MyDrive/ColabNotebooks/log/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjAIRlcvRjJO"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212370,
     "status": "ok",
     "timestamp": 1617370542539,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "_gdL4mbXrtpk",
    "outputId": "3d2fea2f-0ea8-4cba-8f2a-bee82c9694ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.01-0.05.hdf5\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.6552 - accuracy: 0.0478 - top3: 0.0864 - top5: 0.1080\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.02-0.07.hdf5\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.3997 - accuracy: 0.0725 - top3: 0.3611 - top5: 0.4491\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.03-0.82.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.5689 - accuracy: 0.8472 - top3: 0.9460 - top5: 0.9799\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.04-0.87.hdf5\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8796 - top3: 0.9907 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.05-0.90.hdf5\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8719 - top3: 0.9769 - top5: 0.9907\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.06-0.93.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.2474 - accuracy: 0.9151 - top3: 0.9938 - top5: 0.9969\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.07-0.94.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.2400 - accuracy: 0.9213 - top3: 0.9892 - top5: 0.9938\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.08-0.95.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.2251 - accuracy: 0.9336 - top3: 0.9907 - top5: 0.9969\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.09-0.95.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.9537 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.10-0.92.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.9151 - top3: 0.9799 - top5: 0.9938\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.11-0.82.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.8148 - top3: 0.9645 - top5: 0.9830\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.12-0.94.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2609 - accuracy: 0.9259 - top3: 0.9877 - top5: 0.9969\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.13-0.97.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2274 - accuracy: 0.9336 - top3: 0.9877 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.14-0.94.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2187 - accuracy: 0.9414 - top3: 0.9907 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.15-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1228 - accuracy: 0.9614 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.16-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1188 - accuracy: 0.9614 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.17-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1201 - accuracy: 0.9599 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.18-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1315 - accuracy: 0.9614 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.19-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1306 - accuracy: 0.9583 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.20-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1233 - accuracy: 0.9660 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.21-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 0.9645 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.22-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1211 - accuracy: 0.9630 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.23-0.91.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4494 - accuracy: 0.8966 - top3: 0.9707 - top5: 0.9846\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.24-0.92.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3332 - accuracy: 0.9259 - top3: 0.9892 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.25-0.97.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 0.9599 - top3: 0.9907 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.26-0.97.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1484 - accuracy: 0.9537 - top3: 0.9923 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.27-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1585 - accuracy: 0.9568 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.28-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1361 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.29-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1339 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.30-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.31-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1339 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.32-0.97.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1814 - accuracy: 0.9614 - top3: 0.9907 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.33-0.97.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1813 - accuracy: 0.9599 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.34-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9660 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.35-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1610 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.36-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1591 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.37-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1571 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.38-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1563 - accuracy: 0.9645 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.39-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.9660 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.40-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1522 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.41-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1533 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.42-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1557 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.43-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1548 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.44-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1554 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.45-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1555 - accuracy: 0.9599 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.46-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9568 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.47-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1623 - accuracy: 0.9583 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.48-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1603 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.49-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1608 - accuracy: 0.9568 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.50-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1629 - accuracy: 0.9568 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.51-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1589 - accuracy: 0.9583 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.52-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1577 - accuracy: 0.9583 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.53-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1570 - accuracy: 0.9568 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.54-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 0.9568 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.55-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1570 - accuracy: 0.9614 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.56-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1581 - accuracy: 0.9583 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.57-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1557 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.58-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1585 - accuracy: 0.9660 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.59-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1596 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.60-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 0.9660 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.61-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.62-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1599 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.63-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1577 - accuracy: 0.9599 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.64-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1630 - accuracy: 0.9614 - top3: 0.9907 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.65-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1603 - accuracy: 0.9630 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.66-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.9630 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.67-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.9614 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.68-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9599 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.69-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.9599 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.70-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.9614 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.71-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1624 - accuracy: 0.9630 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.72-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.73-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1629 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.74-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1614 - accuracy: 0.9630 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.75-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1629 - accuracy: 0.9614 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.76-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9630 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.77-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9614 - top3: 0.9938 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.78-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9614 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.79-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1638 - accuracy: 0.9614 - top3: 0.9938 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.80-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1664 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.81-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.82-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1638 - accuracy: 0.9614 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.83-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.84-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1615 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.85-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1626 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.86-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1648 - accuracy: 0.9599 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.87-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.9568 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.88-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.9583 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.89-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1647 - accuracy: 0.9583 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.90-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1658 - accuracy: 0.9568 - top3: 0.9954 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.91-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1644 - accuracy: 0.9583 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.92-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1648 - accuracy: 0.9614 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.93-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9614 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.94-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9645 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.95-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1636 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.96-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1638 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.97-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.98-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1688 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.99-0.98.hdf5\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1676 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.100-0.98.hdf5\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1667 - accuracy: 0.9630 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.20-0.98.hdf5  accuracy: 0.9660493731498718\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE THE BEST WEIGHTS to TEST\n",
    "\n",
    "hist_test = {}\n",
    "accuracy_max = 0\n",
    "weights_max = \"\"\n",
    "test_loss, test_accuracy, test_top3, test_top5 = [],[],[],[]\n",
    "for weights in os.listdir(weights_path):\n",
    "    if(weights.endswith(\".hdf5\")):\n",
    "        print(weights)\n",
    "        model.load_weights(weights_path +\"/\"+ weights)\n",
    "        l, a, top3, top5 = model.evaluate(X_test, y_test, verbose=1)\n",
    "        test_loss.append(l)\n",
    "        test_accuracy.append(a)\n",
    "        test_top3.append(top3)\n",
    "        test_top5.append(top5)\n",
    "        if accuracy_max < a:\n",
    "            accuracy_max = a\n",
    "            weights_max = weights\n",
    "        print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(weights_max + \"  accuracy: \" + str(accuracy_max))\n",
    "hist_test = {\"test_loss\":test_loss, \"test_accuracy\":test_accuracy, \"test_top3\":test_top3, \"test_top5\":test_top5}\n",
    "np.save('/content/drive/MyDrive/ColabNotebooks/history_test.npy',hist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249837,
     "status": "ok",
     "timestamp": 1617296457991,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "cBRid4OLvvcR",
    "outputId": "39032124-9c06-46bd-f06f-71121d0cb0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.01-0.04.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 4.0122 - accuracy: 0.0478 - top3: 0.1466 - top5: 0.1667\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.02-0.04.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 3.5577 - accuracy: 0.0494 - top3: 0.3287 - top5: 0.4460\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.04-0.91.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.8974 - top3: 0.9792 - top5: 0.9923\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.05-0.94.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3393 - accuracy: 0.9460 - top3: 0.9877 - top5: 0.9931\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.06-0.96.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2849 - accuracy: 0.9498 - top3: 0.9938 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.07-0.96.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.9383 - top3: 0.9892 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.08-0.96.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3269 - accuracy: 0.9360 - top3: 0.9900 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.09-0.96.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.9321 - top3: 0.9877 - top5: 0.9923\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.10-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2046 - accuracy: 0.9637 - top3: 0.9969 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.11-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2050 - accuracy: 0.9614 - top3: 0.9946 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.12-0.94.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.9329 - top3: 0.9853 - top5: 0.9946\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.13-0.71.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 1.2840 - accuracy: 0.7145 - top3: 0.8773 - top5: 0.9205\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.14-0.93.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.9205 - top3: 0.9815 - top5: 0.9915\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.15-0.97.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2572 - accuracy: 0.9483 - top3: 0.9900 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.16-0.97.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.9568 - top3: 0.9923 - top5: 0.9954\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.17-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1597 - accuracy: 0.9715 - top3: 0.9961 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.18-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.9699 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.19-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9715 - top3: 0.9961 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.20-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9753 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.21-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1464 - accuracy: 0.9707 - top3: 0.9969 - top5: 0.9977\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.22-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.9722 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.23-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9753 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.24-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9722 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.25-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 0.9722 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.26-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1425 - accuracy: 0.9684 - top3: 0.9977 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.27-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9707 - top3: 0.9969 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.28-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1483 - accuracy: 0.9660 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.29-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9684 - top3: 0.9977 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.30-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.9653 - top3: 0.9961 - top5: 0.9985\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.31-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.9738 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.32-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1399 - accuracy: 0.9715 - top3: 0.9985 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.33-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1415 - accuracy: 0.9730 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.34-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1337 - accuracy: 0.9730 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.35-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.9707 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.36-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.9715 - top3: 0.9985 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.37-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.9691 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.38-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1405 - accuracy: 0.9707 - top3: 0.9985 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.39-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1409 - accuracy: 0.9684 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.40-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9645 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.41-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9691 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.42-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9676 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.43-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.9691 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.44-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1560 - accuracy: 0.9653 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.45-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1479 - accuracy: 0.9653 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.46-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1411 - accuracy: 0.9676 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.47-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.9691 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.48-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1356 - accuracy: 0.9676 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.49-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1399 - accuracy: 0.9660 - top3: 0.9992 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.50-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1343 - accuracy: 0.9707 - top3: 0.9992 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.51-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.9691 - top3: 0.9977 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.52-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9699 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.53-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.9668 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.54-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1327 - accuracy: 0.9676 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.55-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.9691 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.56-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1427 - accuracy: 0.9691 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.57-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9699 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.58-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.9676 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.59-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9668 - top3: 0.9977 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.60-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1345 - accuracy: 0.9691 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.61-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.9676 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.62-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.9676 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.63-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.9660 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.64-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1332 - accuracy: 0.9691 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.65-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9707 - top3: 0.9977 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.66-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1376 - accuracy: 0.9676 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.67-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9707 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.68-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9699 - top3: 0.9985 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.69-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.9691 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.70-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1330 - accuracy: 0.9707 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.71-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9684 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.72-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1366 - accuracy: 0.9684 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.73-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 0.9676 - top3: 0.9961 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.74-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9676 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.75-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9699 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.76-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1408 - accuracy: 0.9676 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.77-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9707 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.78-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.9676 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.79-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1403 - accuracy: 0.9637 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.80-0.99.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.9676 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.81-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9676 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.82-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9691 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.83-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1358 - accuracy: 0.9653 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.84-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9660 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.85-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1401 - accuracy: 0.9676 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.86-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9676 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.87-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1387 - accuracy: 0.9676 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.88-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.9676 - top3: 0.9969 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.89-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.9660 - top3: 0.9954 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.90-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9699 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.91-0.98.hdf5\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.9699 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.92-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1374 - accuracy: 0.9668 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.93-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.9668 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.94-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1360 - accuracy: 0.9684 - top3: 0.9954 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.95-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1379 - accuracy: 0.9668 - top3: 0.9954 - top5: 0.9992\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.96-0.99.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1347 - accuracy: 0.9660 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.97-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 0.9653 - top3: 0.9961 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.98-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1361 - accuracy: 0.9653 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.99-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9645 - top3: 0.9969 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.100-0.98.hdf5\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9653 - top3: 0.9946 - top5: 1.0000\n",
      "---------------------------------------------------------------------------------------------\n",
      "weights.20-0.98.hdf5  accuracy: 0.9753086566925049\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE THE BEST WEIGHTS to TEST FLIPPED\n",
    "\n",
    "hist_test = {}\n",
    "accuracy_max = 0\n",
    "weights_max = \"\"\n",
    "test_loss, test_accuracy, test_top3, test_top5 = [],[],[],[]\n",
    "for weights in os.listdir(weights_path):\n",
    "    if(weights.endswith(\".hdf5\")):\n",
    "        print(weights)\n",
    "        model.load_weights(weights_path +\"/\"+ weights)\n",
    "        l, a, top3, top5 = model.evaluate(X_test_flip, y_test_flip, verbose=1)\n",
    "        test_loss.append(l)\n",
    "        test_accuracy.append(a)\n",
    "        test_top3.append(top3)\n",
    "        test_top5.append(top5)\n",
    "        if accuracy_max < a:\n",
    "            accuracy_max = a\n",
    "            weights_max = weights\n",
    "        print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(weights_max + \"  accuracy: \" + str(accuracy_max))\n",
    "hist_test = {\"test_loss\":test_loss, \"test_accuracy\":test_accuracy, \"test_top3\":test_top3, \"test_top5\":test_top5}\n",
    "np.save('/content/drive/MyDrive/ColabNotebooks/history_test_flip.npy',hist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWE1MtXkgSYS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(32, 24))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = predictions.argmax(axis=1)\n",
    "y_label = categorical_to_decoded(y_test, label_enc)\n",
    "y_test_decoded = y_test.argmax(axis=1)\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test_decoded, predictions)    \n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm=matrix, \n",
    "                    normalize    = False,\n",
    "                    target_names = [\"1\",\"2\"],\n",
    "                    title        = \"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA_Q1GWpuEDb"
   },
   "outputs": [],
   "source": [
    "# CHOOSE THE BEST WEIGHTS (TOT, A, B)\n",
    "\n",
    "accuracy_max = 0\n",
    "weights_max = \"\"\n",
    "for weights in os.listdir(weights_path):\n",
    "    if(weights.endswith(\".hdf5\")):\n",
    "        print(weights)\n",
    "        model.load_weights(weights_path +\"/\"+ weights)\n",
    "        lossA, accuracyA = model.evaluate(X_test_A, y_test_A, verbose=1)\n",
    "        lossB, accuracyB = model.evaluate(X_test_B, y_test_B, verbose=1)\n",
    "        loss, accuracy = model.evaluate(X_test_tot, y_test_tot, verbose=1)\n",
    "        loss, accuracy = model.evaluate(X_test_flip, y_test_flip, verbose=1)\n",
    "        if accuracy_max < accuracy:\n",
    "            accuracy_max = accuracy\n",
    "            weights_max = weights\n",
    "        print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(weights_max + \"  accuracy: \" + str(accuracy_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPzb7zleNYWL"
   },
   "outputs": [],
   "source": [
    "# LOAD AND SAVE WEIGHTS AND HISTORY\n",
    "#model.save_weights(\"/content/checkpoint/weights.34-0.71.hdf5\")\n",
    "#model.load_weights(\"/content/checkpoint/weights.02-0.95.hdf5\")\n",
    "\n",
    "#np.save('/content/drive/MyDrive/ColabNotebooks/history.npy',history.history)\n",
    "#history = np.load('/content/drive/MyDrive/ColabNotebooks/history.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scu1rM84NYWM"
   },
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "predictions = model.predict(X_test_tot)\n",
    "\n",
    "get_prediction_data(predictions, X_test_tot, y_test_tot, label_enc, \n",
    "                    summary=False, details=True, plot=(None,\"all\",\"V30\"), y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMzcWcipRCln"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1617370306345,
     "user": {
      "displayName": "Marco Loschiavo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9s3_7KCzffUmLttlgv1bC9AxkHEpGTlOL7vWRvA=s64",
      "userId": "16918725666776522759"
     },
     "user_tz": -120
    },
    "id": "bJ95vct4NYWL",
    "outputId": "da83b696-c081-400a-9cb1-4ce0ac1d2d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT TRAINING AND VALIDATION ACCURACY\n",
    "\n",
    "\n",
    "h = np.load('/content/drive/MyDrive/ColabNotebooks/history_train.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "#h['accuracy'] = h['accuracy'][0:51]\n",
    "#h['val_accuracy'] = h['val_accuracy'][0:51]\n",
    "#h['loss'] = h['loss'][0:51]\n",
    "#h['val_loss'] = h['val_loss'][0:51]\n",
    "\n",
    "plot_train_validation_loss_accuracy2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuDbEefEQ-_s"
   },
   "outputs": [],
   "source": [
    "# PLOT TRAINING AND VALIDATION ACCURACY\n",
    "hist_test = np.load('/content/drive/MyDrive/ColabNotebooks/history_test.npy', allow_pickle='TRUE').item()\n",
    "history = np.load('/content/drive/MyDrive/ColabNotebooks/my_history.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "hist_test['test_accuracy'] = hist_test['test_accuracy'][0:51]\n",
    "hist_test['test_loss'] = hist_test['test_loss'][0:51]\n",
    "history['accuracy'] = history['accuracy'][0:51]\n",
    "history['val_accuracy'] = history['val_accuracy'][0:51]\n",
    "history['loss'] = history['loss'][0:51]\n",
    "history['val_loss'] = history['val_loss'][0:51]\n",
    "\n",
    "plot_train_validation_loss_accuracy3(history, hist_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SpMtW3QsEJ3e",
    "O8VP4h0zdw6Q",
    "34afdsCtSGGx"
   ],
   "name": "classification_VFinal.ipynb",
   "provenance": [
    {
     "file_id": "1IzRZjyQ-Hg8zHJ4COzUXl7HwQdNY0NlX",
     "timestamp": 1611148825127
    },
    {
     "file_id": "1YGK1trHqSwnbprRNfct2uGhqGLd3WEOv",
     "timestamp": 1610610702581
    },
    {
     "file_id": "1tjCTo2xwtSzOLdCK03UVxha8Z6zGDwhK",
     "timestamp": 1610610656662
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
