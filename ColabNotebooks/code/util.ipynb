{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"util.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"}},"cells":[{"cell_type":"code","metadata":{"id":"2DcroWxDA19x"},"source":["import cv2\n","import numpy as np\n","import os\n","import shutil\n","import datetime\n","import math\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split  # Library for split dataset into train and test dataset\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras \n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, MaxPooling2D\n","from keras.utils import plot_model\n","from keras.optimizers import SGD,Adam\n","from keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","\n","\n","# CREA UNA LISTA DI TUTTE LE IMMAGINI NELLA CARTELLA\n","def create_filelist(path, format):\n","    filelist = []\n","    for root, dirs, files in os.walk(path):  # os.walk returns a generator, that creates a tuple of values (current_path, directories in current_path, files in current_path).\n","        for file in files:\n","            if(file.endswith(\".\"+format)):\n","                #append the file name to the list\n","                filelist.append(os.path.join(root,file))\n","    #print('PNG images found in ' + path + ': ', len(filelist))            \n","    return filelist\n","\n","\n","# RITORNA LA LABEL DELL'IMMAGINE DATO IL SUO PATH\n","def path_to_label(path):\n","    file_name_parts = path.split('/')\n","    img_name = file_name_parts[-1]\n","    img_name_parts = img_name.split('_')\n","    return img_name_parts[-1].split('.')[0]\n","\n","\n","# RITORNA UNA LISTA DI IMMAGINI DEL DATASET E UNA LISTA DI LABEL\n","def load_dataset(path, formato):\n","    filelist = create_filelist(path, formato)\n","    X, y = [], []\n","    for file in filelist:\n","        # Leggo immagine\n","        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE) #non Ã¨ normalizzata tra 0 ed 1\n","        #img = mpimg.imread(file)\n","        # Aggiungo immagine aperta al dataset\n","        X.append(img)\n","        # Aggiungo il label dell'immagine aperta al dataset\n","        y.append(path_to_label(file))\n","    return X, y\n","\n","                \n","        \n","# RITORNA LE LABELS CHE HANNO IN COMUNE I DUE DATASET\n","def check_labels_in_common(labels_list1, labels_list2):\n","    labels_comune = []\n","    for l in labels_list1:\n","        for m in labels_list2:\n","            if l == m:\n","                labels_comune.append(l)\n","    return labels_comune\n","\n","\n","# RITORNA IL NUMERO DELLE LABELS PER OGNI CLASSE \n","def get_labels_number_in_category(labels, label_enc=None, view=False, ordina=True):\n","    if labels.ndim == 2:\n","        labels = categorical_to_decoded(labels, label_enc)\n","        all_labels = label_enc.classes_\n","    else:\n","        all_labels = list(set(labels))\n","    dict_labels = dict.fromkeys(set(all_labels), 0) \n","    for l in labels:\n","        dict_labels[l] = dict_labels[l] + 1\n","    #sorted\n","    if ordina == True:\n","        sorted_dict = {}\n","        sorted_keys = sorted(dict_labels, key=dict_labels.get, reverse=True) \n","        for w in sorted_keys:\n","            sorted_dict[w] = dict_labels[w]\n","        dict_labels = sorted_dict\n","    #view  \n","    if view == True:\n","        for k, v in dict_labels.items():\n","            print(k, v)\n","        print(\"tot labels number: \" + str(len(dict_labels)))\n","    return dict_labels\n","\n","\n","# DETTAGLI DEL DATASET\n","def train_test_labels_analysis(y_train, y_test, label_enc=None):\n","    dict_y_train = get_labels_number_in_category(y_train, label_enc)\n","    dict_y_test = get_labels_number_in_category(y_test, label_enc)\n","    n_labels_train, n_labels_test = len(dict_y_train), len(dict_y_test)\n","        \n","    for k, v in dict_y_train.items():\n","        print(k, v , dict_y_test[k])\n","    print(\"labels train number: \" + str(n_labels_train))\n","    print(\"labels test number: \" + str(n_labels_test))\n","\n","    \n","# CONVERTE DA CATEGORICAL A LISTA DECODATA\n","def categorical_to_decoded(y, label_enc):\n","    return label_enc.inverse_transform(np.argmax(y, axis=1))\n","\n","    \n","# RIMUOVE DA DATASET1 LE IMMAGINI CON LABEL CON CONTENUTE IN DATASET2\n","def adjust_dataset1_to_dataset2(dataset_images_1, dataset_labels_1, dataset_images_2, dataset_labels_2):\n","    diff_labels_2 = list(set(dataset_labels_2))  # prendo tutte le label diverse di dataset2\n","    diff_labels_1 = list(set(dataset_labels_1))\n","    labels_comune = check_labels_in_common(dataset_labels_2, dataset_labels_1)\n","    intersect = [l for l in diff_labels_1 if l not in labels_comune]  #label rimanenti in dataset2\n","    dataset_images_1 = [img for i,img in enumerate(dataset_images_1) if dataset_labels_1[i] not in intersect]\n","    dataset_labels_1 = [label for i,label in enumerate(dataset_labels_1) if dataset_labels_1[i] not in intersect]\n","    return dataset_images_1, dataset_labels_1\n","\n","\n","# AGGIUNGE DIMENSIONE EXTRA A IMAGE E LABEL\n","def add_extra_dim(imgs, labels, n_classes):\n","    if imgs.ndim == 3:\n","        imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2], 1))\n","    else:\n","        print(\"error: imgs dataset dimension is \" +str(imgs.ndim)+\" instead 3\")\n","        return\n","    if labels.ndim == 1:\n","        labels = to_categorical(labels, num_classes=n_classes)\n","    else:\n","        print(\"error: labels dataset dimension is \" +str(labels.ndim)+\" instead 1\")\n","        return\n","    return imgs, labels\n","\n","# RIMUOVE DIMENSIONE EXTRA A IMAGE E LABEL\n","def remove_extra_dim(imgs, labels, label_enc):\n","    if imgs.ndim == 4:\n","        imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2]))\n","    else:\n","        print(\"error: imgs dataset dimension is \" +str(imgs.ndim)+\" instead 3\")\n","        return\n","    if labels.ndim == 2:\n","        labels = categorical_to_decoded(labels, label_enc=label_enc)\n","    else:\n","        print(\"error: labels dataset dimension is \" +str(labels.ndim)+\" instead 1\")\n","        return\n","    return imgs, labels\n","\n","        \n","# AUMENTO DEL DATASET\n","def data_augmentation(datagen, images, labels, n_aug):\n","    it = datagen.flow(images, labels, batch_size=1)\n","    for i in range(0, n_aug):\n","        next_it = next(it)\n","        image = next_it[0]\n","        label = next_it[1]\n","        images = np.append(images, image, axis= 0)\n","        labels = np.append(labels, label, axis=0)\n","        #print(\"augmentation of \" + str(i+1) + \" data\")\n","        #plt.imshow(image, cmap=\"gray\")\n","        #plt.show()\n","    return images, labels\n","\n","         \n","        \n","# PLOT TRAIN E VALIDATION LOSS E ACCURACY        \n","def plot_train_validation_loss_accuracy(history):\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","# PLOT TRAIN E VALIDATION LOSS E ACCURACY        \n","def plot_train_validation_loss_accuracy2(history):\n","    print(len(history[\"accuracy\"]))\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['accuracy'])\n","    plt.plot(history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['loss'])\n","    plt.plot(history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","\n","# PLOT TRAIN E VALIDATION LOSS E ACCURACY        \n","def plot_train_validation_loss_accuracy3(history, history_test=None):\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['accuracy'])\n","    plt.plot(history['val_accuracy'])\n","    if history_test != None:\n","        plt.plot(history_test['test_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    if history_test != None:\n","        plt.legend(['train', 'val', 'test'], loc='upper left')\n","    else:\n","        plt.legend(['train', 'val'], loc='upper left')\n","\n","\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['loss'])\n","    plt.plot(history['val_loss'])\n","    if history_test != None:\n","        plt.plot(history_test['test_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    if history_test != None:\n","        plt.legend(['train', 'val', 'test'], loc='upper left')\n","    else:\n","        plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()\n","\n","\n","# PLOT FOR LOCALE\n","def plot(history, history_test=None):\n","\n","    fig, (ax1, ax2) = plt.subplots(2, figsize=(10,7.5))\n","    fig.subplots_adjust(hspace=0.5, top=0.94, bottom=0.08)\n","\n","    ax1.plot(range(1, len(history['accuracy'])+1), history['accuracy'])\n","    ax1.plot(range(1, len(history['val_accuracy'])+1), history['val_accuracy'])\n","    if history_test != None:\n","        ax1.plot(range(1, len(history_test['test_accuracy'])+1), history_test['test_accuracy'])\n","    ax1.set_title('model accuracy')\n","    ax1.set(xlabel='epoch', ylabel='accuracy')\n","    if history_test != None:\n","        ax2.legend(['train', 'val', 'test'], loc='upper left')\n","    else:\n","        ax1.legend(['train', 'val'], loc='upper left')\n","\n","    ax2.plot(range(1, len(history['loss'])+1), history['loss'])\n","    ax2.plot(range(1, len(history['val_loss'])+1), history['val_loss'])\n","    if history_test != None:\n","        ax1.plot(range(1, len(history_test['test_loss'])+1), history_test['test_loss'])\n","    ax2.set_title('model loss')\n","    ax2.set(xlabel='epoch', ylabel='loss')\n","    if history_test != None:\n","        ax2.legend(['train', 'val', 'test'], loc='upper left')\n","    else:\n","        ax2.legend(['train', 'val'], loc='upper left')\n","\n","    plt.show()\n","    \n","\n","\n","def get_prediction_data(predictions, X_test, y_test, label_enc, summary=False, details=False, \n","                        plot=(None,0,None), y_train=None):\n","    print(X_test.shape)\n","    # plot = (plot_type, plot_n)\n","    # plot_type  0 - only corrected pred\n","    #            1 - only wrong pred\n","    #            2 - corrected + wrong pred\n","    #            None\n","    # plot_n     int - number of images to plot\n","    #            \"all\" plot all images\n","    # only_label_to_print     \"S29\" - label of images to plot\n","    #            None\n","    if plot[0] is not None:\n","        plot_type = plot[0]\n","    else:\n","        plot_type = None\n","    plot_n = plot[1]\n","    only_label_to_print = plot[2]\n","    pred_corr = 0\n","    pred_wrong = 0\n","    plot_counter = 0\n","    y_test_decoded = label_enc.inverse_transform(np.argmax(y_test, axis=1))\n","    d_pred_corr = dict.fromkeys(set(y_test_decoded), 0)\n","    d_tot_label = dict.fromkeys(set(y_test_decoded), 0)\n","    if y_train is not None:\n","        d_train_label = get_labels_number_in_category(y_train, label_enc)\n","        \n","    for i,prediction in enumerate(predictions):\n","        p = np.argmax(prediction)\n","        true_label_enc = np.argmax(y_test[i])\n","        true_label = label_enc.inverse_transform([true_label_enc])[0]\n","        d_tot_label[true_label] = d_tot_label[true_label] +1\n","        \n","        if plot_n is \"all\":\n","            plot_n = len(predictions)\n","        \n","        if p == true_label_enc:\n","            pred_corr = pred_corr + 1\n","            d_pred_corr[true_label] = d_pred_corr[true_label] +1\n","            if(summary is True):\n","                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" corrected prediction  \" + \"prediction = \"+ str(p) +\"  true_label_enc = \"+ str(true_label_enc))\n","            \n","            if plot_type is 0 or plot_type is 2 :  \n","                if plot_counter < plot_n:\n","                    if only_label_to_print is not None:\n","                        if str(true_label) == only_label_to_print:\n","                            plt.figure(i)\n","                            plt.imshow(X_test[i], cmap=\"gray\")\n","                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"Â° corrected - \" +\"label \"+ str(true_label))\n","                            plot_counter = plot_counter + 1\n","                    else:        \n","                        plt.figure(i)\n","                        plt.imshow(X_test[i], cmap=\"gray\")\n","                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"Â° corrected - \" +\"label \"+ str(true_label))\n","                        plot_counter = plot_counter + 1\n","                    \n","        else:\n","            pred_wrong = pred_wrong + 1\n","            if summary is True:\n","                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" wrong prediction\")\n","            if plot_type is 1 or plot_type is 2:\n","                if plot_counter < plot_n:   \n","                    if only_label_to_print is not None:\n","                        if str(true_label) == only_label_to_print:\n","                            plt.figure(i)\n","                            plt.imshow(X_test[i], cmap=\"gray\")\n","                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"Â° wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n","                            plot_counter = plot_counter + 1\n","                    else:\n","                        plt.figure(i)\n","                        print(X_test[i].shape)\n","                        plt.imshow(X_test[i], cmap=\"gray\")\n","                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"Â° wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n","                        plot_counter = plot_counter + 1\n","    \n","    if summary is True:\n","        print(\"-------\")\n","        print(\"Corrected predictions: \" + str(pred_corr) + \"/\" + str(len(predictions)) )\n","        print(\"\\n\")\n","    \n","    if details is True:\n","        if y_train is None:\n","            for key in d_tot_label:\n","                print(str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )\n","        else:\n","            for key in d_train_label:\n","                if key in d_tot_label:\n","                    print(str(d_train_label[key]) + \" \"+ str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )    \n","                else:\n","                    print(str(d_train_label[key]) + \" No images in test of label \"+ str(key))\n","        print(\"-------\")\n","        print(\"Correct prediction: \" +str(sum(d_pred_corr.values()))+\"/\"+str(sum(d_tot_label.values())))\n","  \n","    if plot_type is 0 or plot_type is 1 or plot_type is 2 :\n","        plt.show()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfVuMG9SbKXU"},"source":["def lr_schedule_tl(epoch):\n","    initial_lr = 0.0001\n","    lr = initial_lr * ((1/2)**(epoch/30))\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_ft(epoch):\n","    initial_lr = 0.00001\n","    lr = initial_lr * ((1/2)**(epoch/30))\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_semistatic(epoch):\n","    initial_lr = 0.0003\n","    lr = initial_lr * ((1/2)**(epoch/100) )\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule(epoch):\n","    initial_lr = 0.0005\n","    lr = initial_lr * ((1/2)**(epoch/15) )\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_old_new(epoch):\n","    initial_lr = 0.001\n","    every = 15\n","    lr = initial_lr*(1/2)**(math.floor(epoch/every))\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_old(epoch):\n","    initial_lr = 0.001\n","    if epoch<=15:\n","        lr = initial_lr\n","    elif epoch<=30:\n","        lr = initial_lr/2\n","    elif epoch<=45:\n","        lr = initial_lr/4 \n","    elif epoch<=60:\n","        lr = initial_lr/8 \n","    elif epoch<=75:\n","        lr = initial_lr/16\n","    elif epoch<=90:\n","        lr = initial_lr/32\n","    else:\n","        lr = initial_lr/64 \n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_resnet(epoch):\n","    initial_lr = 0.0003\n","    lr = initial_lr * ((1/2)**(epoch/30) )\n","    print('current learning rate is %2.8f' %lr)\n","    return lr\n","\n","\n","def lr_schedule_exp(epoch):\n","    initial_lr = 0.001\n","    k = 0.05\n","    lrate = initial_lrate * exp(-k*epoch)\n","    print('current learning rate is %2.8f' %lr)\n","    return lrate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZkC-AcEj-J0P"},"source":["# SALVATAGGIO DATASET\n","\n","#salva dataset su disco\n","def save_dataset(path, X, y, formato=\"jpg\", subpath=False, horizontal_flip=False):\n","    if os.path.isdir(path):\n","        shutil.rmtree(path)\n","    os.makedirs(path)\n","\n","    if subpath is False:  # salva tutti i file in path(non crea sottocartelle)\n","        for i,img in enumerate(X):\n","            flip = cv2.flip(img, 1)\n","            #print(\"img\",np.max(img), np.min(img))\n","            #print(\"flip\", np.max(flip), np.min(flip))\n","            cv2.imwrite(path + \"/\" + \"%04d\" % (i+1) + \"_\" + str(y[i]) + \".\" + formato, img)\n","            if horizontal_flip is True:\n","                cv2.imwrite(path + \"/\" + \"%04d\" % (i+1) + \"HF_\" + str(y[i]) + \".\" + formato, cv2.flip(img, 1)) \n","        print(\"dataset created\")\n","\n","    else:  # salva tutti i file in subpath(crea una cartella per ogni classe)\n","        subpath_list = []\n","        for i,img in enumerate(X):\n","            flip = cv2.flip(img, 1)\n","            print(\"img\",np.max(img), np.min(img))\n","            print(\"flip\", np.max(flip), np.min(flip))\n","            if y[i] not in subpath_list:\n","                os.mkdir(path+\"/\"+y[i])\n","                subpath_list.append(y[i])\n","            cv2.imwrite(path + \"/\" + y[i] + \"/\" + \"%04d\" % (i+1) + \"_\" + str(y[i]) + \".\" + formato, img)   \n","            if horizontal_flip is True:\n","                cv2.imwrite(path + \"/\" + y[i] + \"/\" + \"%04d\" % (i+1) + \"HF_\" + str(y[i]) + \".\" + formato, cv2.flip(img, 1)) \n","        print(\"dataset created\")"],"execution_count":null,"outputs":[]}]}